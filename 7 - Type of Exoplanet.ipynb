{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> Using Machine Learning to Classify Exoplanets </h1>\n",
    "\n",
    "Ben Douglass\n",
    "\n",
    "January 16, 2016\n",
    "\n",
    "Big Data\n",
    "\n",
    "Period 8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Astrophysicists have started finding exoplanets over the past couple decades, and numbers of discoveries have just begun skyrocketing. To aid exoplanet discoverers, they could input three characteristics they can determine about the planet into my code, and it would give them a 91.8% accurate answer of what type of exoplanet they have discovered. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3530, 4)\n",
      "[[ 1.    2.    0.64]\n",
      " [ 1.    2.    4.86]\n",
      " [ 1.    2.    2.79]\n",
      " ..., \n",
      " [ 3.    1.    0.23]\n",
      " [ 3.    1.    0.21]\n",
      " [ 3.    1.    0.22]]\n",
      "[ 5.  5.  5. ...,  5.  5.  5.]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "#import exoplanet list\n",
    "exoplanet_file = open(\"exoplanet_parameters.csv\", 'r');\n",
    "\n",
    "#create numpy matrix\n",
    "dataset = np.loadtxt(exoplanet_file, delimiter=\",\")\n",
    "\n",
    "print (dataset.shape)\n",
    "\n",
    "#set up inputs (x) and outputs (y) \n",
    "X = dataset[:,1:4]\n",
    "y = dataset[:,0]\n",
    "\n",
    "print(X)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, I am setting up my data in input and output numpy matrices. The X matrix is my input with 3 columns for each of the three features, and the y matrix is the outputs (0-5)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Finding which algorithm works best: DecisionTree, KNeighbors, and Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.92181303116147306, 0.91614730878186967, 0.90141643059490084, 0.91274787535410762, 0.91558073654390937, 0.91444759206798865, 0.9048158640226629, 0.91274787535410762, 0.91558073654390937, 0.92237960339943348]\n",
      "Average Accuracy of DecisionTree: 0.913767705382\n",
      "\n",
      "[0.92351274787535409, 0.91898016997167142, 0.91218130311614731, 0.91218130311614731, 0.90878186968838526, 0.91104815864022659, 0.90991501416430598, 0.91614730878186967, 0.91614730878186967, 0.92124645892351276]\n",
      "Average Accuracy of KNeighbors 0.915014164306\n",
      "\n",
      "[0.92634560906515584, 0.9178470254957507, 0.91274787535410762, 0.91331444759206803, 0.91501416430594906, 0.91614730878186967, 0.91671388101982998, 0.91614730878186967, 0.92237960339943348, 0.9240793201133144]\n",
      "Average Accuracy of RandomForest 0.918073654391\n"
     ]
    }
   ],
   "source": [
    "from sklearn import datasets\n",
    "import random\n",
    "import statistics\n",
    "from sklearn.cross_validation import train_test_split\n",
    "\n",
    "counter = 0 \n",
    "list_one = []\n",
    "list_two = []\n",
    "list_three = []\n",
    "\n",
    "\n",
    "while counter < 10:\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = .5)\n",
    "    \n",
    "    from sklearn import tree\n",
    "    tree_classifier = tree.DecisionTreeClassifier();\n",
    "    tree_classifier = tree_classifier.fit(X_train, y_train)\n",
    "    tree_predictions = tree_classifier.predict(X_test)\n",
    "\n",
    "    from sklearn.metrics import accuracy_score\n",
    "    data = (accuracy_score(tree_predictions, y_test))\n",
    "    list_one.append(data);\n",
    "    \n",
    "    \n",
    "    from sklearn import neighbors\n",
    "    knn_classifier = neighbors.KNeighborsClassifier()\n",
    "    knn_classifier = knn_classifier.fit(X_train, y_train)\n",
    "    knn_predictions = knn_classifier.predict(X_test)\n",
    "\n",
    "    data2 = (accuracy_score(knn_predictions, y_test))\n",
    "    list_two.append(data2);\n",
    "    \n",
    "    \n",
    "    from sklearn import ensemble\n",
    "    rf_classifier = ensemble.RandomForestClassifier()\n",
    "    rf_classifier = rf_classifier.fit(X_train, y_train)\n",
    "    rf_predictions = rf_classifier.predict(X_test)\n",
    "\n",
    "    data3 = (accuracy_score(rf_predictions, y_test))\n",
    "    list_three.append(data3)\n",
    "    \n",
    "    counter+=1\n",
    "    \n",
    "print(list_one)\n",
    "print(\"Average Accuracy of DecisionTree:\", statistics.mean(list_one))\n",
    "print ( )\n",
    "print(list_two)\n",
    "print(\"Average Accuracy of KNeighbors\", statistics.mean(list_two))\n",
    "print ( )\n",
    "print(list_three)\n",
    "print(\"Average Accuracy of RandomForest\", statistics.mean(list_three))\n",
    "\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I found that the most accurate algorithm was <b>RandomForest</b> because it has an accuracy score of 0.918, whereas KNeighbors is behind with 0.915 and DecisionTree has 0.914. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn import ensemble\n",
    "rf_classifier = ensemble.RandomForestClassifier()\n",
    "rf_classifier = rf_classifier.fit(X_train, y_train)\n",
    "\n",
    "sample1 = input(\"Planet Zone Class (1 = cold, 2 = warm, 3 = hot): \")\n",
    "sample2 = input(\"Planet Atmosphere Class(0 = no atmosphere, 1 = metals-rich, 2 = hydrogen-rich): \")\n",
    "sample3 = input(\"Planet Density (Earth Units): \")\n",
    "\n",
    "print( )\n",
    "print (\"I am 91.9% sure that this exoplanet is:\")\n",
    "\n",
    "rf_predictions = rf_classifier.predict([[sample1, sample2, sample3]])\n",
    "if rf_predictions == 0:\n",
    "    print (\"Mercurian\");\n",
    "elif rf_predictions == 1:\n",
    "    print (\"Subterran\");\n",
    "elif rf_predictions == 2:\n",
    "    print (\"Terran\");\n",
    "elif rf_predictions == 3:\n",
    "    print (\"Superterran\");\n",
    "elif rf_predictions == 4:\n",
    "    print (\"Neptunian\")\n",
    "elif rf_predictions == 5:\n",
    "    print (\"Jovian\");\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The goal of this code is for an astrophysicist to be able to find 3 characteristics of a planet and simply plug them in to point them in the right direction of what type of planet they might have discovered. The three characteristics I chose were planet density (in Earth Units), the Zone Class (cold, warm, hot), and the type of atmosphere (none, metals-rich, hydrogen-rich). I chose density because I thought it would help me tell the difference between giants (jovian and neptunian) and terran (mercurian, subterran, terran, superterran) planets. I chose zone class because it tells how far away a planet is from its star with regard to the size of the star itself (if I had used distance from star I would not know what to make of it because 1 Astronomical Unit could be a frozen planet around a small star or literally inside a large star). I also chose type the of atmosphere because I thought it would again help me tell the difference between jovian planets and rocky planets, except I also thought it would further help me figure out the difference between types of rocky planets because usually only the smallest planets don’t have atmospheres. All three of these an astrophysicist can relatively easily determine, which was my goal so this concept could potentially be useful. The output is the mass class of the planet (mercurian, subterran, terran, superterran, Neptunian, and jovian). This is basically what type of planet it is, just as the planets in our solar system are classified generally as the gas giants and the rocky planets. \n",
    "\n",
    "I think it is difficult in choosing which aspects of the planet really best match each other. Some of my properties ended up dominating: Planet Density and Atmosphere class. There are some trends in the inputs that were interesting:\n",
    "\n",
    "Things that will make the planet “Jovian” pretty much regardless of the other inputs are density and planet atmosphere. If the planet is very high density, then it is very likely jovian. If the planet has a hydrogen-rich atmosphere, it is probably jovian. This was a very common output.\n",
    "\n",
    "Additionally, the planet was often “Terran” if the atmosphere class was metals-rich. I found it interesting that it was usually “Terran” specifically, and less often the other types of rocky planets. This was also a very common output.\n",
    "\n",
    "I would get “Superterran” when I had essentially a “terran” planet but with a higher density.  \n",
    "\n",
    "It was difficult to get “Mercurian”. This was partially because there were so few mercurian planets that existed in my data, so you had to get pretty close to the exact data for it to see that its mercurian. This could cause problems if this were used in the real world because there are many other variations of mercurian planets, and just a few mercurian planets does not establish enough of a pattern. \n",
    "\n",
    "I additionally had a hard time finding “Subterran” planets without using exact numbers from the data. I think this is a similar situation to Mercurian planets, however there were some more Subterran planets so I was surprised that this case was similar to Mercurian planets. \n",
    "\n",
    "It would often get “Neptunian” when I greatly lowered the density. This initially seemed odd to me, but upon looking through the data again I indeed found that a lot of Neptunian planets were low-density. Additionally, I did some research about our own solar system and found that Neptune’s density is only 0.297 in Earth Units, and Uranus’ density is 0.23 Earth Units. \n",
    "\n",
    "\n",
    "\n",
    "Zone class did not have much of an impact on the output. This one I was not as sure would impact the output, but I thought it would be interesting to test. I guessed that rocky planets would generally be closer to their stars than gas giants, just like in our own solar system. It turns out, different types of planets can be found at all kinds of distances from their stars. I even did some research afterward and found that there are many hot gas giants, which suprises me. It may be that our own solar system is a bit of an anomaly that the planets are so split with gas giants being far away and rocky planets being so close up. \n",
    "\n",
    "\n",
    "I had hoped that a method similar to this could help lead scientists in the right direction when working on classifying exoplanets. Though it may lead them in the right direction, I think it often may lead them more toward certain types of planets like Terran and Jovian planets more than others, thus potantially misleading them from the other types of planets. I now think this would not be such a good idea for scientists to use, however it would still be interesting to use this on new planets without giving too much weight and see how accurate the currents trends we can see in the data remain as we discover more worlds. If the accuracy remains up with new planets we discover, then maybe it should be taken more seriously. Otherwise, I think it’s just fun to make up your own planet with. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
